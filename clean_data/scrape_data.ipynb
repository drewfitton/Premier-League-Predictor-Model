{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping for League Results and Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Working Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data_out')\n",
    "# Replace with the path to your chromedriver\n",
    "CHROMEDRIVER_DIR = os.path.join(BASE_DIR, 'chromedriver-mac-x64','chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Season URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURLs():\n",
    "    curr_year = datetime.now().year\n",
    "\n",
    "    seasons = list(reversed(range(curr_year - 20, curr_year)))\n",
    "\n",
    "    root_url = 'https://www.oddsportal.com/soccer/england/premier-league'\n",
    "    results_path = '/results/'\n",
    "    results_url = root_url + results_path\n",
    "\n",
    "    #Get URLs for results pages for every season\n",
    "    seasons_url = [root_url + '-' + str(season) + '-' + str(season + 1) + results_path for season in seasons]\n",
    "\n",
    "    #complete url list to be scraped\n",
    "    return [results_url] + seasons_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize scroll function to click page links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scroll_to_element_and_click(driver, element):\n",
    "    # Scroll the element into view\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)\n",
    "    # Add a small delay if needed for any animation or page shift\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        button = driver.find_element(By.ID, \"onetrust-accept-btn-handler\")  # Replace with the actual button ID\n",
    "        button.click()\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        print(\"No cookies!\")\n",
    "    # Click the element after scrolling\n",
    "    element.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WebScrape OddsPortal for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n",
      "No cookies!\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n0   chromedriver                        0x0000000109a77f68 chromedriver + 7110504\n1   chromedriver                        0x0000000109a6ff6a chromedriver + 7077738\n2   chromedriver                        0x00000001094110f0 chromedriver + 397552\n3   chromedriver                        0x000000010945d383 chromedriver + 709507\n4   chromedriver                        0x000000010945d681 chromedriver + 710273\n5   chromedriver                        0x00000001094a2e14 chromedriver + 994836\n6   chromedriver                        0x000000010948193d chromedriver + 858429\n7   chromedriver                        0x00000001094a0234 chromedriver + 983604\n8   chromedriver                        0x00000001094816b3 chromedriver + 857779\n9   chromedriver                        0x0000000109450182 chromedriver + 655746\n10  chromedriver                        0x000000010945115e chromedriver + 659806\n11  chromedriver                        0x0000000109a3d3b0 chromedriver + 6869936\n12  chromedriver                        0x0000000109a412e4 chromedriver + 6886116\n13  chromedriver                        0x0000000109a1f9b7 chromedriver + 6748599\n14  chromedriver                        0x0000000109a41d6e chromedriver + 6888814\n15  chromedriver                        0x0000000109a0ec84 chromedriver + 6679684\n16  chromedriver                        0x0000000109a5e838 chromedriver + 7006264\n17  chromedriver                        0x0000000109a5e9f6 chromedriver + 7006710\n18  chromedriver                        0x0000000109a6fb78 chromedriver + 7076728\n19  libsystem_pthread.dylib             0x00007ff81537018b _pthread_start + 99\n20  libsystem_pthread.dylib             0x00007ff81536bae3 thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#Get every page for current URL\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpagination\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m pagination_container \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagination\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m pagination_links \u001b[38;5;241m=\u001b[39m pagination_container\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagination-link\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/PremierLeaguePredictor/.conda/lib/python3.11/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n0   chromedriver                        0x0000000109a77f68 chromedriver + 7110504\n1   chromedriver                        0x0000000109a6ff6a chromedriver + 7077738\n2   chromedriver                        0x00000001094110f0 chromedriver + 397552\n3   chromedriver                        0x000000010945d383 chromedriver + 709507\n4   chromedriver                        0x000000010945d681 chromedriver + 710273\n5   chromedriver                        0x00000001094a2e14 chromedriver + 994836\n6   chromedriver                        0x000000010948193d chromedriver + 858429\n7   chromedriver                        0x00000001094a0234 chromedriver + 983604\n8   chromedriver                        0x00000001094816b3 chromedriver + 857779\n9   chromedriver                        0x0000000109450182 chromedriver + 655746\n10  chromedriver                        0x000000010945115e chromedriver + 659806\n11  chromedriver                        0x0000000109a3d3b0 chromedriver + 6869936\n12  chromedriver                        0x0000000109a412e4 chromedriver + 6886116\n13  chromedriver                        0x0000000109a1f9b7 chromedriver + 6748599\n14  chromedriver                        0x0000000109a41d6e chromedriver + 6888814\n15  chromedriver                        0x0000000109a0ec84 chromedriver + 6679684\n16  chromedriver                        0x0000000109a5e838 chromedriver + 7006264\n17  chromedriver                        0x0000000109a5e9f6 chromedriver + 7006710\n18  chromedriver                        0x0000000109a6fb78 chromedriver + 7076728\n19  libsystem_pthread.dylib             0x00007ff81537018b _pthread_start + 99\n20  libsystem_pthread.dylib             0x00007ff81536bae3 thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "service = Service(executable_path=CHROMEDRIVER_DIR)\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(2)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "unique_matches = set()  # To track unique matches\n",
    "\n",
    "all_urls = getURLs()\n",
    "# Iterate over urls for seasons\n",
    "for url in all_urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    #Get every page for current URL\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pagination')))\n",
    "    pagination_container = driver.find_element(By.CLASS_NAME, 'pagination')\n",
    "    pagination_links = pagination_container.find_elements(By.CLASS_NAME, 'pagination-link')\n",
    "\n",
    "    if len(pagination_links) > 1:\n",
    "        pagination_links = pagination_links[:-1]\n",
    "\n",
    "    previous_page = None\n",
    "\n",
    "    for link in pagination_links:\n",
    "        current_page = link.get_attribute(\"data-number\")\n",
    "        \n",
    "        # Click the pagination link and wait for the page to load\n",
    "        if previous_page:\n",
    "            #print(f\"Navigating from page {previous_page} to page {current_page}\")\n",
    "            link.click()\n",
    "        else:\n",
    "            #print(f\"Starting from page {current_page}\")\n",
    "            scroll_to_element_and_click(driver, link)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'eventRow')))\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        for row in soup.find_all('div', class_='eventRow'):\n",
    "            if row.find('div', class_='text-black-main font-main w-full truncate text-xs font-normal leading-5'):\n",
    "                curr_date = row.find('div', class_='text-black-main font-main w-full truncate text-xs font-normal leading-5').text.strip()\n",
    "\n",
    "            if len(row.find_all('p', attrs={'data-v-18e31eaa': True})) >= 2 and len(row.find_all('p', class_='participant-name truncate')) > 1:\n",
    "                home_team = row.find_all('p', class_='participant-name truncate')[0].text.strip()\n",
    "                away_team = row.find_all('p', class_='participant-name truncate')[1].text.strip()\n",
    "\n",
    "                # Create a unique identifier for each match\n",
    "                match_id = (curr_date, home_team, away_team)\n",
    "\n",
    "                if match_id not in unique_matches:\n",
    "                    unique_matches.add(match_id)  # Add the match to the set\n",
    "                    new_row = pd.DataFrame([{\n",
    "                        'season': soup.find('a', 'active-item-calendar').text.strip(),\n",
    "                        'date': curr_date,\n",
    "                        'home_team': home_team,\n",
    "                        'away_team': away_team,\n",
    "                        'h_goals': row.find_all('div', class_='min-mt:!flex')[0].text.strip(),\n",
    "                        'a_goals': row.find_all('div', class_='min-mt:!flex')[1].text.strip(),\n",
    "                        'h_odds': row.find_all('p', attrs={'data-v-18e31eaa': True})[0].text.strip(),\n",
    "                        'd_odds': row.find_all('p', attrs={'data-v-18e31eaa': True})[1].text.strip(),\n",
    "                        'a_odds': row.find_all('p', attrs={'data-v-18e31eaa': True})[2].text.strip()\n",
    "                    }])\n",
    "                    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "        previous_page = current_page\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_DIR,  'matches.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
